{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44QyEHb7GPXX"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow keras pillow pyttsx3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jtWunsT-Gi8k"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b15KaIWpGnNB"
      },
      "outputs": [],
      "source": [
        "!pip install Opendatasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "b1-iD32jhA70"
      },
      "outputs": [],
      "source": [
        "import opendatasets as od\n",
        "import pandas\n",
        "data_dir = od.download(\n",
        "    \"https://www.kaggle.com/datasets/adityajn105/flickr8k\",\n",
        "force='True',\n",
        "    data_dir ='flickr8k_data'  # Specify a different extraction directory\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "U3az2t8lULQf"
      },
      "outputs": [],
      "source": [
        "!pip install gTTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5hlOTSguGvMy"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import json\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.applications import ResNet50, MobileNet\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input as preprocess_input_resnet\n",
        "from tensorflow.keras.applications.mobilenet import preprocess_input as preprocess_input_mobilenet\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, Add\n",
        "from gtts import gTTS\n",
        "import pyttsx3\n",
        "import IPython.display as ipd\n",
        "from pycocotools.coco import COCO\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rwvgeS7QMog5"
      },
      "outputs": [],
      "source": [
        "data_dir = \"/content/flickr8k_data/flickr8k\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5gsbWWDzMvZk"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "data_dir= pathlib.Path(data_dir)  #to add dataset path in directory\n",
        "data_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "E37T-HwiUZku"
      },
      "outputs": [],
      "source": [
        "list(data_dir.glob('*/*.jpg'))[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5THqQQi1WSkT"
      },
      "outputs": [],
      "source": [
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "print(image_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6zIe4G6lWV9v"
      },
      "outputs": [],
      "source": [
        "# Load libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import keras\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Dense, Flatten,Input, Convolution2D, Dropout, LSTM, TimeDistributed, Embedding, Bidirectional, Activation, RepeatVector,Concatenate\n",
        "from keras.models import Sequential, Model\n",
        "# np_utils has been moved to tensorflow.keras.utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import random\n",
        "from keras.preprocessing import image, sequence\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input as preprocess_resnet50, decode_predictions as decode_resnet50\n",
        "from tensorflow.keras.applications.mobilenet import preprocess_input as preprocess_mobilenet, decode_predictions as decode_mobilenet\n",
        "from tensorflow.keras.applications import ResNet50, MobileNet\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Concatenate, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "import torch\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "from PIL import Image\n",
        "import requests\n",
        "from gtts import gTTS\n",
        "import IPython.display as ipd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TQhEhB_qWbyD"
      },
      "outputs": [],
      "source": [
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "print(image_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Q039jImtWfBS"
      },
      "outputs": [],
      "source": [
        "# Load the BLIP processor and model\n",
        "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LZB_uRjGWior"
      },
      "outputs": [],
      "source": [
        "\n",
        "def load_and_preprocess_image(img_path, target_size):\n",
        "    img = image.load_img(img_path, target_size=target_size)\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    return img_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9QLd7oTIWlz1"
      },
      "outputs": [],
      "source": [
        "# Function to add prefix to layer names\n",
        "def add_prefix_to_layers(model, prefix):\n",
        "    for layer in model.layers:\n",
        "        layer._name = prefix + layer.name\n",
        "\n",
        "# Load Pretrained Models\n",
        "resnet_model = ResNet50(weights='imagenet', include_top=False)\n",
        "add_prefix_to_layers(resnet_model, \"resnet_\")\n",
        "\n",
        "mobilenet_model = MobileNet(weights='imagenet', include_top=False)\n",
        "add_prefix_to_layers(mobilenet_model, \"mobilenet_\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YgBvQxc5WrHr"
      },
      "outputs": [],
      "source": [
        "# Load Pretrained Models\n",
        "resnet_model = ResNet50(weights='imagenet', include_top=False)\n",
        "mobilenet_model = MobileNet(weights='imagenet', include_top=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9Fv6XLnSWunI"
      },
      "outputs": [],
      "source": [
        "img_path = \"/content/flickr8k_data/flickr8k/Images/1007320043_627395c3d8.jpg\"  # Removed extra '.jpg' from the file name\n",
        "img_resnet50 = preprocess_resnet50(load_and_preprocess_image(img_path, target_size=(224, 224)))\n",
        "img_mobilenet = preprocess_mobilenet(load_and_preprocess_image(img_path, target_size=(224, 224)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3lJ8AxTrXD0k"
      },
      "outputs": [],
      "source": [
        "def create_hybrid_model():\n",
        "    resnet_input = Input(shape=(224, 224, 3), name='resnet_input')\n",
        "    mobilenet_input = Input(shape=(224, 224, 3), name='mobilenet_input')\n",
        "\n",
        "    resnet_output = resnet_model(resnet_input)\n",
        "    mobilenet_output = mobilenet_model(mobilenet_input)\n",
        "\n",
        "    x_resnet50 = GlobalAveragePooling2D()(resnet_output)\n",
        "    x_mobilenet = GlobalAveragePooling2D()(mobilenet_output)\n",
        "\n",
        "    concatenated = Concatenate()([x_resnet50, x_mobilenet])\n",
        "    predictions = Dense(1000, activation='softmax')(concatenated)\n",
        "\n",
        "    model = Model(inputs=[resnet_input, mobilenet_input], outputs=predictions)\n",
        "    return model\n",
        "\n",
        "hybrid_model = create_hybrid_model()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2iZPoxCrXHAb"
      },
      "outputs": [],
      "source": [
        "def load_and_preprocess_image(img_path, target_size):\n",
        "    img = image.load_img(img_path, target_size=target_size)\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    return img_array\n",
        "\n",
        "img_path = '/content/flickr8k_data/flickr8k/Images/1001773457_577c3a7d70.jpg'  # replace with your image path\n",
        "img_resnet50 = preprocess_resnet50(load_and_preprocess_image(img_path, target_size=(224, 224)))\n",
        "img_mobilenet = preprocess_mobilenet(load_and_preprocess_image(img_path, target_size=(224, 224)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7cZPi_3xGyig"
      },
      "outputs": [],
      "source": [
        "# Make prediction\n",
        "preds = hybrid_model.predict([img_resnet50, img_mobilenet])\n",
        "predicted_class = np.argmax(preds[0])\n",
        "\n",
        "# Load ImageNet labels\n",
        "!wget https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
        "import json\n",
        "with open('imagenet_class_index.json', 'r') as f:\n",
        "    class_dict = json.load(f)\n",
        "class_labels = {int(key): value[1] for key, value in class_dict.items()}\n",
        "\n",
        "predicted_label = class_labels[predicted_class]\n",
        "print(\"Predicted label:\", predicted_label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6Y9Q96VVXWuP"
      },
      "outputs": [],
      "source": [
        "# Extract Features\n",
        "features = hybrid_model.predict([img_resnet50, img_mobilenet])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ei3FxzeHXYZh"
      },
      "outputs": [],
      "source": [
        "# Ensure transformers library is installed\n",
        "!pip install -q transformers\n",
        "\n",
        "from transformers import GPT2Tokenizer, TFGPT2LMHeadModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cFWcqK2TXdsp"
      },
      "outputs": [],
      "source": [
        "# Load the tokenizer and the model\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "captioning_model = TFGPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "\n",
        "# Prepare input for the model\n",
        "input_ids = tokenizer.encode(\"Features: \", return_tensors=\"tf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iKV8hDPoXkTq"
      },
      "outputs": [],
      "source": [
        "# Generate caption\n",
        "output = captioning_model.generate(input_ids, max_length=50, num_return_sequences=1)\n",
        "caption = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "print(\"Generated caption:\", caption)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "u18cIzcaXrhl"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess image\n",
        "img_path = \"/content/flickr8k_data/flickr8k/Images/1001773457_577c3a7d70.jpg\"  # Local file path\n",
        "img = Image.open(img_path) # Open the image directly\n",
        "inputs = processor(img, return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "txUtmcp2YETF"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers\n",
        "from transformers import BlipForConditionalGeneration\n",
        "\n",
        "# Assuming 'model' was originally a PretrainedResNetModel, replace it with:\n",
        "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "\n",
        "# Now, the 'generate' method should be available\n",
        "output = model.generate(**inputs)\n",
        "caption = processor.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "print(\"Generated caption:\", caption)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "z_ZyRHjvlcLf"
      },
      "outputs": [],
      "source": [
        "!pip install googletrans==4.0.0-rc1 gtts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fuFO9hyjliZu"
      },
      "outputs": [],
      "source": [
        "from googletrans import Translator\n",
        "from gtts import gTTS\n",
        "import IPython.display as ipd\n",
        "\n",
        "# Prompt user for language code\n",
        "def get_language_code():\n",
        "    # List of language codes for common languages\n",
        "    languages = {\n",
        "        'English': 'en',\n",
        "        'Spanish': 'es',\n",
        "        'French': 'fr',\n",
        "        'German': 'de',\n",
        "        'Chinese': 'zh',\n",
        "        'Japanese': 'ja',\n",
        "        'Korean': 'ko',\n",
        "        'Italian': 'it',\n",
        "        'Hindi': 'hi',\n",
        "        'Tamil': 'ta',\n",
        "        'Bengali': 'bn',\n",
        "        'Telugu': 'te',\n",
        "        'Punjabi': 'pa',\n",
        "        'Marathi': 'mr',\n",
        "        'Russian': 'ru',\n",
        "        'Arabic': 'ar',\n",
        "        'Portuguese': 'pt',\n",
        "        'Dutch': 'nl',\n",
        "        'Swedish': 'sv',\n",
        "        'Norwegian': 'no',\n",
        "        'Greek': 'el',\n",
        "        'Turkish': 'tr',\n",
        "        'Persian': 'fa',\n",
        "    }\n",
        "\n",
        "    print(\"Available languages:\")\n",
        "    for lang_name, lang_code in languages.items():\n",
        "        print(f\"{lang_name}: {lang_code}\")\n",
        "\n",
        "    lang_choice = input(\"Enter the language code (e.g., 'en', 'es'): \").strip()\n",
        "    return lang_choice if lang_choice in languages.values() else 'en'  # Default to 'en' if not found\n",
        "\n",
        "# Translate text to the desired language\n",
        "def translate_text(text, dest_lang):\n",
        "    translator = Translator()\n",
        "    translated = translator.translate(text, dest=dest_lang)\n",
        "    return translated.text\n",
        "\n",
        "# Convert text to speech\n",
        "def text_to_speech(text, lang='en'):\n",
        "    tts = gTTS(text=text, lang=lang)\n",
        "    tts.save('caption.mp3')\n",
        "    return 'caption.mp3'\n",
        "\n",
        "# Example usage\n",
        "language_code = get_language_code()  # Get language code from user\n",
        "translated_caption = translate_text(caption, language_code)  # Translate caption\n",
        "print(f\"Translated Caption: {translated_caption}\")\n",
        "voice_output = text_to_speech(translated_caption, lang=language_code)  # Generate speech\n",
        "\n",
        "# Play the audio\n",
        "ipd.display(ipd.Audio(voice_output))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UBPTfXmf5EtU"
      },
      "outputs": [],
      "source": [
        "# Bagging - wrong output\n",
        "from collections import Counter\n",
        "\n",
        "def bagging_ensemble(caption_file_path):\n",
        "    \"\"\"\n",
        "    Performs bagging ensemble on captions from a file.\n",
        "\n",
        "    Args:\n",
        "        caption_file_path: Path to the file containing captions, one per line.\n",
        "\n",
        "    Returns:\n",
        "        The most frequent caption.\n",
        "    \"\"\"\n",
        "    with open(caption_file_path, 'r') as f:\n",
        "        captions = [line.strip() for line in f]\n",
        "\n",
        "    return Counter(captions).most_common(1)[0][0]\n",
        "\n",
        "# Example usage:\n",
        "caption_file_path = \"/content/flickr8k_data/flickr8k/captions.txt\" # Replace with your actual file path\n",
        "result = bagging_ensemble(caption_file_path)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Va6o0E82Djas"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Placeholder - Replace these with your actual data\n",
        "x_data = torch.randn(100, 3, 224, 224)  # Example: 100 samples with 3 channels (RGB) and 224x224 dimensions\n",
        "y_data = torch.randint(0, 2, (100, 1)).float()  # Example: 100 binary target values\n",
        "\n",
        "# Create a dataset (Do not normalize yet)\n",
        "dataset = TensorDataset(x_data, y_data)\n",
        "\n",
        "# Split the data into train and test sets (80-20 split)\n",
        "train_size = int(0.8 * len(x_data))\n",
        "test_size = len(x_data) - train_size\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "from torchvision import models\n",
        "\n",
        "class PretrainedResNetModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PretrainedResNetModel, self).__init__()\n",
        "        self.resnet = models.resnet50(pretrained=True)\n",
        "        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.resnet(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "# Initialize model, loss function, and optimizer\n",
        "model = PretrainedResNetModel()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)  # Lower learning rate for fine-tuning\n",
        "\n",
        "from torchvision.transforms import ToTensor, Normalize, Compose, Resize\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, x, y, transform=None):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.x[idx]\n",
        "        y = self.y[idx]\n",
        "        # Ensure x is in the shape [C, H, W] before applying transforms\n",
        "        if x.dim() == 2:  # If it's a 2D tensor, assume it's grayscale and add a channel dimension\n",
        "            x = x.unsqueeze(0)\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "        return x, y\n",
        "\n",
        "# Define the transformations - Remove ToTensor as the data is already in Tensor format\n",
        "transform = Compose([\n",
        "    Resize((224, 224)),  # Resize images to 224x224\n",
        "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet mean and std\n",
        "])\n",
        "\n",
        "# Create the DataLoader\n",
        "train_loader = DataLoader(CustomDataset(train_dataset.dataset.tensors[0], train_dataset.dataset.tensors[1], transform=transform), batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(CustomDataset(test_dataset.dataset.tensors[0], test_dataset.dataset.tensors[1], transform=transform), batch_size=32, shuffle=False)\n",
        "        # Continue with the rest of your training loop logic here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jGuCd2hJFSLV"
      },
      "outputs": [],
      "source": [
        "# Define the model with Pretrained ResNet\n",
        "class PretrainedResNetModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PretrainedResNetModel, self).__init__()\n",
        "        self.resnet = models.resnet50(pretrained=True)\n",
        "        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.resnet(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "# Initialize model, loss function, and optimizer\n",
        "model = PretrainedResNetModel().to(torch.float32)  # Ensure model parameters are in float32\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.BCELoss().to(device)  # Ensure loss function is on the correct device\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rc8Oxow0FOKl"
      },
      "outputs": [],
      "source": [
        "# Convert data tensors to float32\n",
        "x_data = torch.tensor(x_data, dtype=torch.float32)\n",
        "y_data = torch.tensor(y_data, dtype=torch.float32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qO2EvJRpjr0T"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomCrop(224, padding=4),  # Add random cropping\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1), # Add color jittering\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "     # Apply this transform when creating your datasets and dataloaders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tsMUT3itkRPP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "\n",
        "# ... (Your existing code for data loading, dataset creation, etc.)\n",
        "\n",
        "class PretrainedResNetModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PretrainedResNetModel, self).__init__()\n",
        "        self.resnet = models.resnet50(pretrained=True)\n",
        "        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.dropout = nn.Dropout(0.5)  # Add dropout layer here\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.resnet(x)\n",
        "        x = self.dropout(x)  # Apply dropout before sigmoid\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "# Use weight decay in your optimizer:\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9l--bSJxiRuX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bb36cdd-3d84-439f-bf36-dacdd3a59c6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Loss: 0.9300, Training Accuracy: 0.5100\n",
            "Epoch 2/20, Loss: 0.5065, Training Accuracy: 0.5100\n",
            "Epoch 3/20, Loss: 0.4473, Training Accuracy: 0.5100\n",
            "Epoch 4/20, Loss: 0.4571, Training Accuracy: 0.5100\n",
            "Epoch 5/20, Loss: 0.4788, Training Accuracy: 0.5100\n",
            "Epoch 6/20, Loss: 0.2632, Training Accuracy: 0.5100\n",
            "Epoch 7/20, Loss: 0.0835, Training Accuracy: 0.5100\n",
            "Epoch 8/20, Loss: 0.0810, Training Accuracy: 0.5100\n",
            "Epoch 9/20, Loss: 0.0141, Training Accuracy: 0.5100\n",
            "Epoch 10/20, Loss: 0.0283, Training Accuracy: 0.5100\n",
            "Epoch 11/20, Loss: 0.0091, Training Accuracy: 0.5100\n",
            "Epoch 12/20, Loss: 0.0040, Training Accuracy: 0.5100\n",
            "Epoch 13/20, Loss: 0.0033, Training Accuracy: 0.5100\n",
            "Epoch 14/20, Loss: 0.1146, Training Accuracy: 0.5100\n",
            "Epoch 15/20, Loss: 0.1630, Training Accuracy: 0.5100\n",
            "Epoch 16/20, Loss: 0.2566, Training Accuracy: 0.5100\n",
            "Epoch 17/20, Loss: 0.1033, Training Accuracy: 0.5100\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "epochs = 20\n",
        "for epoch in range(epochs):\n",
        "     model.train()\n",
        "     epoch_loss = 0\n",
        "     y_true_train = []  # To store true labels for the training set\n",
        "     y_pred_train = []  # To store predicted labels for the training set\n",
        "\n",
        "     for batch_x, batch_y in train_loader:\n",
        "         batch_x, batch_y = batch_x.to(device).to(torch.float32), batch_y.to(device).to(torch.float32)\n",
        "\n",
        "         optimizer.zero_grad()\n",
        "         outputs = model(batch_x)\n",
        "         loss = criterion(outputs, batch_y)\n",
        "         loss.backward()\n",
        "         optimizer.step()\n",
        "\n",
        "         epoch_loss += loss.item()\n",
        "\n",
        "         # Get predictions and true labels for accuracy calculation\n",
        "         _, predicted = torch.max(outputs, 1)\n",
        "         y_true_train.extend(batch_y.cpu().numpy())\n",
        "         y_pred_train.extend(predicted.cpu().numpy())\n",
        "\n",
        "     epoch_loss /= len(train_loader)\n",
        "     train_accuracy = accuracy_score(y_true_train, y_pred_train)  # Calculate accuracy\n",
        "     print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Training Accuracy: {train_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_aEfPNDKFZgT"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "# Evaluate the model\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score # Import necessary metrics\n",
        "\n",
        "model.eval()\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_x, batch_y in test_loader:\n",
        "        batch_x, batch_y = batch_x.to(device).to(torch.float32), batch_y.to(device).to(torch.float32)\n",
        "        outputs = model(batch_x).cpu().numpy()\n",
        "        y_true.extend(batch_y.cpu().numpy())\n",
        "        y_pred.extend(outputs)\n",
        "\n",
        "# Convert predictions to binary (0 or 1)\n",
        "y_pred = (np.array(y_pred) > 0.5).astype(int)\n",
        "y_true = np.array(y_true).astype(int)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "# Plot metrics\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "metrics = {\n",
        "    'Accuracy': accuracy,\n",
        "    'Precision': precision,\n",
        "    'Recall': recall,\n",
        "    'F1 Score': f1\n",
        "}\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(metrics.keys(), metrics.values(), color=['b', 'g', 'r', 'c'])\n",
        "plt.title('Evaluation Metrics')\n",
        "plt.ylabel('Score')\n",
        "plt.ylim(0, 1)\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UiOa8Zw5rhVi"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def calculate_mcc(tp, tn, fp, fn):\n",
        "    \"\"\"\n",
        "    Calculate the Matthews Correlation Coefficient (MCC).\n",
        "\n",
        "    Parameters:\n",
        "    tp (int): True Positives\n",
        "    tn (int): True Negatives\n",
        "    fp (int): False Positives\n",
        "    fn (int): False Negatives\n",
        "\n",
        "    Returns:\n",
        "    float: The MCC score\n",
        "    \"\"\"\n",
        "    # Calculate the MCC\n",
        "    numerator = (tp * tn) - (fp * fn)\n",
        "    denominator = np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
        "\n",
        "    if denominator == 0:\n",
        "        return 0.0  # Return 0 if the denominator is zero to avoid division by zero\n",
        "\n",
        "    return numerator / denominator\n",
        "\n",
        "# Calculate tp, tn, fp, fn from y_true and y_pred\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "\n",
        "mcc_score = calculate_mcc(tp, tn, fp, fn)\n",
        "print(f'MCC Score: {mcc_score:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76-iHlakeT0x"
      },
      "outputs": [],
      "source": [
        "!pip install matplotlib seaborn\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Assuming y_true and y_pred are available as NumPy arrays\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Plot the confusion matrix using Seaborn\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nN8jwkBRr7qa"
      },
      "outputs": [],
      "source": [
        "y_pred_proba = model(batch_x).detach().cpu().numpy()  # Store probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WyB3OB7tsM3M"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
        "\n",
        "model.eval()\n",
        "y_true = []\n",
        "y_pred = []\n",
        "y_pred_proba = []  # Store probabilities for all batches\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_x, batch_y in test_loader:\n",
        "        batch_x, batch_y = batch_x.to(device).to(torch.float32), batch_y.to(device).to(torch.float32)\n",
        "        outputs = model(batch_x)\n",
        "        y_true.extend(batch_y.cpu().numpy())\n",
        "        y_pred.extend(outputs.cpu().numpy() > 0.5)  # Directly store binary predictions\n",
        "        y_pred_proba.extend(outputs.cpu().numpy())  # Store probabilities\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "y_true = np.array(y_true).astype(int)\n",
        "y_pred = np.array(y_pred).astype(int)\n",
        "y_pred_proba = np.array(y_pred_proba).squeeze()  # Squeeze to get a 1D array of probabilities\n",
        "\n",
        "\n",
        "# Calculate ROC curve and AUC\n",
        "fpr, tpr, thresholds = roc_curve(y_true, y_pred_proba)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "print(f'ROC AUC: {roc_auc:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbEEiLtnsWkC"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5lNZnLXs-r4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "variance = np.var(y_pred_proba)\n",
        "print(\"Variance of model predictions:\", variance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDwSenmjvV_9"
      },
      "outputs": [],
      "source": [
        "def count_layers(model):\n",
        "    \"\"\"Counts the number of layers in a PyTorch model.\"\"\"\n",
        "    layer_count = 0\n",
        "    for name, module in model.named_modules():\n",
        "        if isinstance(module, (torch.nn.Linear, torch.nn.Conv2d, torch.nn.BatchNorm2d, torch.nn.ReLU, torch.nn.MaxPool2d)):  # Add other layer types as needed\n",
        "            layer_count += 1\n",
        "    return layer_count\n",
        "\n",
        "num_layers = count_layers(model)\n",
        "print(f\"The model has {num_layers} layers.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z44iVtsz2jBK"
      },
      "outputs": [],
      "source": [
        "# Assuming 'model' is your PyTorch model, 'test_data', and 'test_labels' are your test data\n",
        "import torch\n",
        "\n",
        "# Define your loss function\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# ... (Your PyTorch evaluation loop)\n",
        "model.eval()  # Set model to evaluation mode\n",
        "with torch.no_grad():\n",
        "    outputs = model(x_data)\n",
        "    # Assuming 'predicted_label' should be a tensor of class indices\n",
        "    # Replace this with the actual way to get the correct class indices for your data\n",
        "    predicted_label = torch.tensor([0] * len(outputs))  # Example: all samples belong to class 0\n",
        "    loss = criterion(outputs, predicted_label)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    top1_accuracy = (predicted == predicted_label).sum().item() / len(predicted_label)\n",
        "\n",
        "print(\"Test Loss:\",loss.item())\n",
        "print(\"Top-1 Accuracy:\", top1_accuracy)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}